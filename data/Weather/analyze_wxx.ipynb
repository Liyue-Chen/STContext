{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对收集的数据的收集和简单处理完毕，接下来进行进一步处理和分析  \n",
    "（收集和简单处理的代码，详见pa_wxx.ipynb）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nkey: 观测站点的唯一标识符\\nclass: 观测的类别\\nexpire_time_gmt: 观测的过期时间\\nobs_id: 观测的ID\\nobs_name: 观测站点的名称\\nvalid_time_gmt: 观测的有效时间\\nday_ind: 一天中的时间段（白天或晚上）\\ntemp: 温度（华氏度）\\nwx_icon: 天气图标的代码\\nicon_extd: 天气图标的扩展代码\\nwx_phrase: 天气短语描述\\npressure_tend: 气压变化趋势\\npressure_desc: 气压描述\\ndewPt: 露点温度（华氏度）\\nheat_index: 酷热指数\\nrh: 相对湿度\\npressure: 气压\\nvis: 能见度（英里）\\nwc: 风寒指数\\nwdir: 风向（角度）\\nwdir_cardinal: 风向的助记符号\\ngust: 风速瞬时值（英里/小时）\\nwspd: 风速（英里/小时）\\nmax_temp: 最高温度（华氏度）\\nmin_temp: 最低温度（华氏度）\\nprecip_total: 总降水量（英寸）\\nprecip_hrly: 每小时降水量（英寸）\\nsnow_hrly: 每小时降雪量（英寸）\\nuv_desc: 紫外线指数描述\\nfeels_like: 体感温度（华氏度）\\nuv_index: 紫外线指数\\nqualifier: 气象数据的限定条件\\nqualifier_svrty: 限定条件的严重程度\\nblunt_phrase: 概括的天气短语描述\\nterse_phrase: 简短的天气短语描述\\nclds: 云量\\nwater_temp: 水温\\nprimary_wave_period: 主波周期\\nprimary_wave_height: 主波高度\\nprimary_swell_period: 主涌浪周期\\nprimary_swell_height: 主涌浪高度\\nprimary_swell_direction: 主涌浪方向\\nsecondary_swell_period: 次涌浪周期\\nsecondary_swell_height: 次涌浪高度\\nsecondary_swell_direction: 次涌浪方向'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "后续需将以下数据说明仿照kaggle: https://www.kaggle.com/datasets\n",
    "\n",
    "key: 观测站点的唯一标识符\n",
    "class: 观测的类别\n",
    "expire_time_gmt: 观测的过期时间\n",
    "obs_id: 观测的ID\n",
    "obs_name: 观测站点的名称\n",
    "valid_time_gmt: 观测的有效时间\n",
    "day_ind: 一天中的时间段（白天或晚上）\n",
    "temp: 温度（华氏度）\n",
    "wx_icon: 天气图标的代码\n",
    "icon_extd: 天气图标的扩展代码\n",
    "wx_phrase: 天气短语描述\n",
    "pressure_tend: 气压变化趋势 (0-稳定, 1-上升, 2-下降)\n",
    "pressure_desc: 气压描述 (其实就是前一字段的描述)\n",
    "dewPt: 露点温度（华氏度）\n",
    "heat_index: 酷热指数\n",
    "rh: 相对湿度\n",
    "pressure: 气压\n",
    "vis: 能见度（英里）\n",
    "wc: 风寒指数\n",
    "wdir: 风向（角度） —— —— 以北, 顺时针的角度(取值范围10-360), 360代表北 \n",
    "wdir_cardinal: 风向的助记符号\n",
    "gust: 风速瞬时值（英里/小时）\n",
    "wspd: 风速（英里/小时）\n",
    "max_temp: 最高温度（华氏度）\n",
    "min_temp: 最低温度（华氏度）\n",
    "precip_total: 总降水量（英寸）\n",
    "precip_hrly: 每小时降水量（英寸）\n",
    "snow_hrly: 每小时降雪量（英寸）\n",
    "uv_desc: 紫外线指数描述\n",
    "feels_like: 体感温度（华氏度）\n",
    "uv_index: 紫外线指数 https://www.epa.gov/sunsafety/calculating-uv-index-0\n",
    "\n",
    "(以下列除了clds，都无数据，只是爬取时有该列，但是并没有数据)\n",
    "qualifier: 气象数据的限定条件\n",
    "qualifier_svrty: 限定条件的严重程度\n",
    "blunt_phrase: 概括的天气短语描述\n",
    "terse_phrase: 简短的天气短语描述\n",
    "clds: 云量 https://www.eoas.ubc.ca/courses/atsc113/flying/met_concepts/01-met_concepts/01c-cloud_coverage/index.html\n",
    "water_temp: 水温\n",
    "primary_wave_period: 主波周期\n",
    "primary_wave_height: 主波高度\n",
    "primary_swell_period: 主涌浪周期\n",
    "primary_swell_height: 主涌浪高度\n",
    "primary_swell_direction: 主涌浪方向\n",
    "secondary_swell_period: 次涌浪周期\n",
    "secondary_swell_height: 次涌浪高度\n",
    "secondary_swell_direction: 次涌浪方向\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 数据非空率、分布情况（词频率）、异常值比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAY Number of rows: 4849\n",
      "Chicago Number of rows: 43734\n",
      "DC Number of rows: 47368\n",
      "LA Number of rows: 3197\n",
      "Melbourne Number of rows: 240747\n",
      "NYC Number of rows: 43431\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cities_ls = ['BAY','Chicago','DC','LA','Melbourne','NYC']\n",
    "suffix = 'Weather_ori_1.csv'\n",
    "# col = ['STATION', 'STATION_NAME', 'ELEVATION', 'LATITUDE', 'LONGITUDE', 'DATE', 'REPORTTYPE', 'HOURLYSKYCONDITIONS', 'HOURLYVISIBILITY', 'HOURLYPRSENTWEATHERTYPE', 'HOURLYDRYBULBTEMPF', 'HOURLYDRYBULBTEMPC', 'HOURLYWETBULBTEMPF', 'HOURLYWETBULBTEMPC', 'HOURLYDewPointTempF', 'HOURLYDewPointTempC', 'HOURLYRelativeHumidity', 'HOURLYWindSpeed', 'HOURLYWindDirection', 'HOURLYWindGustSpeed', 'HOURLYStationPressure', 'HOURLYPressureTendency', 'HOURLYPressureChange', 'HOURLYSeaLevelPressure', 'HOURLYPrecip', 'HOURLYAltimeterSetting', 'DAILYMaximumDryBulbTemp', 'DAILYMinimumDryBulbTemp', 'DAILYAverageDryBulbTemp', 'DAILYDeptFromNormalAverageTemp', 'DAILYAverageRelativeHumidity', 'DAILYAverageDewPointTemp', 'DAILYAverageWetBulbTemp', 'DAILYHeatingDegreeDays', 'DAILYCoolingDegreeDays', 'DAILYSunrise', 'DAILYSunset', 'DAILYWeather', 'DAILYPrecip', 'DAILYSnowfall', 'DAILYSnowDepth', 'DAILYAverageStationPressure', 'DAILYAverageSeaLevelPressure', 'DAILYAverageWindSpeed', 'DAILYPeakWindSpeed', 'PeakWindDirection', 'DAILYSustainedWindSpeed', 'DAILYSustainedWindDirection', 'MonthlyMaximumTemp', 'MonthlyMinimumTemp', 'MonthlyMeanTemp', 'MonthlyAverageRH', 'MonthlyDewpointTemp', 'MonthlyWetBulbTemp', 'MonthlyAvgHeatingDegreeDays', 'MonthlyAvgCoolingDegreeDays', 'MonthlyStationPressure', 'MonthlySeaLevelPressure', 'MonthlyAverageWindSpeed', 'MonthlyTotalSnowfall', 'MonthlyDeptFromNormalMaximumTemp', 'MonthlyDeptFromNormalMinimumTemp', 'MonthlyDeptFromNormalAverageTemp', 'MonthlyDeptFromNormalPrecip', 'MonthlyTotalLiquidPrecip', 'MonthlyGreatestPrecip', 'MonthlyGreatestPrecipDate', 'MonthlyGreatestSnowfall', 'MonthlyGreatestSnowfallDate', 'MonthlyGreatestSnowDepth', 'MonthlyGreatestSnowDepthDate', 'MonthlyDaysWithGT90Temp', 'MonthlyDaysWithLT32Temp', 'MonthlyDaysWithGT32Temp', 'MonthlyDaysWithLT0Temp', 'MonthlyDaysWithGT001Precip', 'MonthlyDaysWithGT010Precip', 'MonthlyDaysWithGT1Snow', 'MonthlyMaxSeaLevelPressureValue', 'MonthlyMaxSeaLevelPressureDate', 'MonthlyMaxSeaLevelPressureTime', 'MonthlyMinSeaLevelPressureValue', 'MonthlyMinSeaLevelPressureDate', 'MonthlyMinSeaLevelPressureTime', 'MonthlyTotalHeatingDegreeDays', 'MonthlyTotalCoolingDegreeDays', 'MonthlyDeptFromNormalHeatingDD', 'MonthlyDeptFromNormalCoolingDD', 'MonthlyTotalSeasonToDateHeatingDD', 'MonthlyTotalSeasonToDateCoolingDD']\n",
    "col = ['key', 'class', 'expire_time_gmt', 'obs_id', 'obs_name', 'valid_time_gmt', \n",
    "         'day_ind', 'temp', 'wx_icon', 'icon_extd', 'wx_phrase', 'pressure_tend', \n",
    "         'pressure_desc', 'dewPt', 'heat_index', 'rh', 'pressure', 'vis', 'wc', \n",
    "         'wdir', 'wdir_cardinal', 'gust', 'wspd', 'max_temp', 'min_temp', \n",
    "         'precip_total', 'precip_hrly', 'snow_hrly', 'uv_desc', 'feels_like', \n",
    "         'uv_index', 'qualifier', 'qualifier_svrty', 'blunt_phrase', 'terse_phrase', \n",
    "         'clds', 'water_temp', 'primary_wave_period', 'primary_wave_height', \n",
    "         'primary_swell_period', 'primary_swell_height', 'primary_swell_direction', \n",
    "         'secondary_swell_period', 'secondary_swell_height', 'secondary_swell_direction']\n",
    "# 适合分析和画图的列\n",
    "draw_col = ['temp', 'wx_phrase', 'pressure_tend', 'pressure_desc',\\\n",
    "            'dewPt', 'heat_index', 'rh', 'pressure', 'vis', 'wc',\\\n",
    "            'wdir', 'wdir_cardinal', 'gust', 'wspd', 'max_temp',\\\n",
    "            'min_temp', 'precip_total', 'precip_hrly', 'snow_hrly',\\\n",
    "            'uv_desc', 'feels_like', 'uv_index', 'clds', ]\n",
    "\n",
    "for c in cities_ls:\n",
    "    f_str = c + suffix # the name of the file\n",
    "    df_statistics = pd.read_csv(f_str)\n",
    "    num_rows = len(df_statistics)\n",
    "    print(c, \"Number of rows:\", num_rows)\n",
    "\n",
    "    # 统计一下数据的非空率（即 1 减去 缺失率 ）\n",
    "    prop_non_null_df = pd.DataFrame(columns=col)\n",
    "    for col_name in col:\n",
    "        prop_non_null = df_statistics[col_name].count() / num_rows\n",
    "        prop_non_null_df.loc[0, col_name] = prop_non_null\n",
    "        \n",
    "    prop_non_null_path = f'./statistics/{c}/'\n",
    "    prop_non_null_file = c+'Weather_ori_1_prop_non_null.csv'\n",
    "    if not os.path.exists(prop_non_null_path):\n",
    "        os.makedirs(prop_non_null_path)\n",
    "    prop_non_null_df.to_csv(prop_non_null_path+prop_non_null_file,\\\n",
    "                          index=False)\n",
    "    \n",
    "    # 统计一下分布情况\n",
    "    for col_name in draw_col:\n",
    "        distribution = df_statistics[col_name].value_counts() / num_rows\n",
    "        if len(distribution) == 0: continue\n",
    "        distribution_path = f'./statistics/{c}/distribution/'\n",
    "        if not os.path.exists(distribution_path):\n",
    "            os.makedirs(distribution_path)\n",
    "        distribution_file = c+f'Weather_ori_1_{col_name}.csv'\n",
    "        distribution.to_csv(distribution_path+distribution_file)\n",
    "        \n",
    "        distribution.sort_index(inplace=True) # 先根据索引值排序\n",
    "        # 区域图\n",
    "        distribution.plot.area(x=distribution.index, stacked=False)\n",
    "\n",
    "        # 折线图\n",
    "        # distribution.plot.line()\n",
    "\n",
    "        # 柱状图\n",
    "        # distribution.plot.bar()\n",
    "\n",
    "        plt.grid(color = 'r', linestyle = '--', linewidth = 0.5)\n",
    "        if col_name == 'wx_phrase': plt.xticks(rotation=15)\n",
    "        plt.savefig((distribution_path+distribution_file)[:-4], dpi=300)\n",
    "        plt.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAY Number of rows: 4849\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Worksheet 'Sheet' does not exist.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a866cccc6087>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mopenpyxl\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWorkbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_workbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[0mwb_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutlier_value_path_2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34mf'_ALL_Weather_ori_1_outlier_value.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m     \u001b[0mws_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwb_2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquote_sheetname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Sheet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m     \u001b[0mwb_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mws_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[0mwb_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutlier_value_path_2\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34mf'_ALL_Weather_ori_1_outlier_value.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\ANACONDA\\lib\\site-packages\\openpyxl\\workbook\\workbook.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    271\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msheet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0msheet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Worksheet {0} does not exist.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Worksheet 'Sheet' does not exist.\""
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from openpyxl import Workbook\n",
    "\n",
    "cities_ls = ['BAY','Chicago','DC','LA','Melbourne','NYC']\n",
    "suffix = 'Weather_ori_1.csv'\n",
    "# col = ['STATION', 'STATION_NAME', 'ELEVATION', 'LATITUDE', 'LONGITUDE', 'DATE', 'REPORTTYPE', 'HOURLYSKYCONDITIONS', 'HOURLYVISIBILITY', 'HOURLYPRSENTWEATHERTYPE', 'HOURLYDRYBULBTEMPF', 'HOURLYDRYBULBTEMPC', 'HOURLYWETBULBTEMPF', 'HOURLYWETBULBTEMPC', 'HOURLYDewPointTempF', 'HOURLYDewPointTempC', 'HOURLYRelativeHumidity', 'HOURLYWindSpeed', 'HOURLYWindDirection', 'HOURLYWindGustSpeed', 'HOURLYStationPressure', 'HOURLYPressureTendency', 'HOURLYPressureChange', 'HOURLYSeaLevelPressure', 'HOURLYPrecip', 'HOURLYAltimeterSetting', 'DAILYMaximumDryBulbTemp', 'DAILYMinimumDryBulbTemp', 'DAILYAverageDryBulbTemp', 'DAILYDeptFromNormalAverageTemp', 'DAILYAverageRelativeHumidity', 'DAILYAverageDewPointTemp', 'DAILYAverageWetBulbTemp', 'DAILYHeatingDegreeDays', 'DAILYCoolingDegreeDays', 'DAILYSunrise', 'DAILYSunset', 'DAILYWeather', 'DAILYPrecip', 'DAILYSnowfall', 'DAILYSnowDepth', 'DAILYAverageStationPressure', 'DAILYAverageSeaLevelPressure', 'DAILYAverageWindSpeed', 'DAILYPeakWindSpeed', 'PeakWindDirection', 'DAILYSustainedWindSpeed', 'DAILYSustainedWindDirection', 'MonthlyMaximumTemp', 'MonthlyMinimumTemp', 'MonthlyMeanTemp', 'MonthlyAverageRH', 'MonthlyDewpointTemp', 'MonthlyWetBulbTemp', 'MonthlyAvgHeatingDegreeDays', 'MonthlyAvgCoolingDegreeDays', 'MonthlyStationPressure', 'MonthlySeaLevelPressure', 'MonthlyAverageWindSpeed', 'MonthlyTotalSnowfall', 'MonthlyDeptFromNormalMaximumTemp', 'MonthlyDeptFromNormalMinimumTemp', 'MonthlyDeptFromNormalAverageTemp', 'MonthlyDeptFromNormalPrecip', 'MonthlyTotalLiquidPrecip', 'MonthlyGreatestPrecip', 'MonthlyGreatestPrecipDate', 'MonthlyGreatestSnowfall', 'MonthlyGreatestSnowfallDate', 'MonthlyGreatestSnowDepth', 'MonthlyGreatestSnowDepthDate', 'MonthlyDaysWithGT90Temp', 'MonthlyDaysWithLT32Temp', 'MonthlyDaysWithGT32Temp', 'MonthlyDaysWithLT0Temp', 'MonthlyDaysWithGT001Precip', 'MonthlyDaysWithGT010Precip', 'MonthlyDaysWithGT1Snow', 'MonthlyMaxSeaLevelPressureValue', 'MonthlyMaxSeaLevelPressureDate', 'MonthlyMaxSeaLevelPressureTime', 'MonthlyMinSeaLevelPressureValue', 'MonthlyMinSeaLevelPressureDate', 'MonthlyMinSeaLevelPressureTime', 'MonthlyTotalHeatingDegreeDays', 'MonthlyTotalCoolingDegreeDays', 'MonthlyDeptFromNormalHeatingDD', 'MonthlyDeptFromNormalCoolingDD', 'MonthlyTotalSeasonToDateHeatingDD', 'MonthlyTotalSeasonToDateCoolingDD']\n",
    "col = ['key', 'class', 'expire_time_gmt', 'obs_id', 'obs_name', 'valid_time_gmt', \n",
    "         'day_ind', 'temp', 'wx_icon', 'icon_extd', 'wx_phrase', 'pressure_tend', \n",
    "         'pressure_desc', 'dewPt', 'heat_index', 'rh', 'pressure', 'vis', 'wc', \n",
    "         'wdir', 'wdir_cardinal', 'gust', 'wspd', 'max_temp', 'min_temp', \n",
    "         'precip_total', 'precip_hrly', 'snow_hrly', 'uv_desc', 'feels_like', \n",
    "         'uv_index', 'qualifier', 'qualifier_svrty', 'blunt_phrase', 'terse_phrase', \n",
    "         'clds', 'water_temp', 'primary_wave_period', 'primary_wave_height', \n",
    "         'primary_swell_period', 'primary_swell_height', 'primary_swell_direction', \n",
    "         'secondary_swell_period', 'secondary_swell_height', 'secondary_swell_direction']\n",
    "# 适合分析和画图的列\n",
    "draw_col = ['temp', 'wx_phrase', 'pressure_tend', 'pressure_desc',\\\n",
    "            'dewPt', 'heat_index', 'rh', 'pressure', 'vis', 'wc',\\\n",
    "            'wdir', 'wdir_cardinal', 'gust', 'wspd', 'max_temp',\\\n",
    "            'min_temp', 'precip_total', 'precip_hrly', 'snow_hrly',\\\n",
    "            'uv_desc', 'feels_like', 'uv_index', 'clds', ]\n",
    "\n",
    "\n",
    "for c in cities_ls:\n",
    "    f_str = c + suffix # the name of the file\n",
    "    df_statistics = pd.read_csv(f_str)\n",
    "    num_rows = len(df_statistics)\n",
    "    print(c, \"Number of rows:\", num_rows)\n",
    "\n",
    "    outlier_ratio_df = pd.DataFrame(columns=col) # 异常值比例\n",
    "    # 以数据为主的列，以及可能出现异常值的列\n",
    "    number_col = ['temp', 'pressure_tend', 'dewPt', \\\n",
    "                    'heat_index', 'rh', 'pressure', 'vis', 'wc',\\\n",
    "                    'wdir', 'gust', 'wspd', 'max_temp',\\\n",
    "                    'min_temp', 'precip_total', 'precip_hrly', 'snow_hrly',\\\n",
    "                    'feels_like', 'uv_index', ]\n",
    "    df_2_list = [] # 超过2标准差的异常值列表\n",
    "    df_3_list = [] # 超过3标准差的异常值列表\n",
    "\n",
    "    for col_name in number_col:\n",
    "        # 1. 统计异常值（大于两个标准差）比例\n",
    "        data = df_statistics[col_name]\n",
    "        if len(data) == 0: continue\n",
    "\n",
    "        mean = data.mean()\n",
    "        std = data.std()\n",
    "\n",
    "        mask_2 = (data-mean).abs() > 2 * std\n",
    "        mask_3 = (data-mean).abs() > 3 * std\n",
    "\n",
    "        outlier_ratio_2 = mask_2.mean()\n",
    "        outlier_ratio_3 = mask_3.mean()\n",
    "        outlier_ratio_df.loc['std', col_name] = std\n",
    "        outlier_ratio_df.loc['ratio_out_std_2', col_name] = outlier_ratio_2\n",
    "        outlier_ratio_df.loc['ratio_out_std_3', col_name] = outlier_ratio_3\n",
    "\n",
    "        # 2. 查找异常值\n",
    "        dict_find_2 = {'valid_time_gmt':[], col_name:[]} # 两个标准差\n",
    "        dict_find_3 = {'valid_time_gmt':[], col_name:[]} # 三个标准差\n",
    "        data_find = df_statistics.loc[:, ['valid_time_gmt', col_name]]\n",
    "        for i in range(len(mask_2)):\n",
    "            if mask_2[i] == 1:\n",
    "                dict_find_2['valid_time_gmt'].append(data_find.iloc[i, 0])\n",
    "                dict_find_2[col_name].append(data_find.iloc[i, 1])\n",
    "            if mask_3[i] == 1:\n",
    "                dict_find_3['valid_time_gmt'].append(data_find.iloc[i, 0])\n",
    "                dict_find_3[col_name].append(data_find.iloc[i, 1])\n",
    "        outlier_value_2_df = pd.DataFrame(dict_find_2)\n",
    "        outlier_value_3_df = pd.DataFrame(dict_find_3)\n",
    "        df_2_list.append(outlier_value_2_df)\n",
    "        df_3_list.append(outlier_value_3_df)\n",
    "\n",
    "        outlier_value_path_2 = f'./statistics/{c}/outlier_value_2std/'  \n",
    "        outlier_value_path_3 = f'./statistics/{c}/outlier_value_3std/'\n",
    "        outlier_value_file = c+f'Weather_ori_1_{col_name}_outlier_value.csv'\n",
    "        \n",
    "        if not os.path.exists(outlier_value_path_2):\n",
    "            os.makedirs(outlier_value_path_2)\n",
    "        if not os.path.exists(outlier_value_path_3):\n",
    "            os.makedirs(outlier_value_path_3)\n",
    "        outlier_value_2_df.to_csv(outlier_value_path_2+outlier_value_file,\\\n",
    "                          index=False)\n",
    "        outlier_value_3_df.to_csv(outlier_value_path_3+outlier_value_file,\\\n",
    "                          index=False)\n",
    "    \n",
    "    wb_2 = Workbook()\n",
    "    wb_2.save(outlier_value_path_2+c+f'_ALL_Weather_ori_1_outlier_value.xlsx')\n",
    "    wb_3 = Workbook()\n",
    "    wb_3.save(outlier_value_path_3+c+f'_ALL_Weather_ori_1_outlier_value.xlsx')\n",
    "    for df, col_name in zip(df_2_list,number_col):\n",
    "        with pd.ExcelWriter(outlier_value_path_2+c+f'_ALL_Weather_ori_1_outlier_value.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "            writer.book = wb_2\n",
    "            df.to_excel(writer, sheet_name=col_name)\n",
    "    for df, col_name in zip(df_3_list,number_col):\n",
    "        with pd.ExcelWriter(outlier_value_path_3+c+f'_ALL_Weather_ori_1_outlier_value.xlsx', engine='openpyxl', mode='a') as writer:\n",
    "            writer.book = wb_3\n",
    "            df.to_excel(writer, sheet_name=col_name)\n",
    "\n",
    "    # writer_2 = pd.ExcelWriter(outlier_value_path_2+c+f'_ALL_Weather_ori_1_outlier_value.xlsx' ,mode='a',engine='openpyxl')\n",
    "    # writer_3 = pd.ExcelWriter(outlier_value_path_3+c+f'_ALL_Weather_ori_1_outlier_value.xlsx' ,mode='a',engine='openpyxl')\n",
    "    # for df, col_name in zip(df_2_list,number_col):\n",
    "    #     df.to_excel(writer_2, col_name)\n",
    "    # for df, col_name in zip(df_3_list,number_col):\n",
    "    #     df.to_excel(writer_3, col_name)\n",
    "    # writer_2.save()\n",
    "    # writer_2.close()\n",
    "    # writer_3.save()\n",
    "    # writer_3.close()\n",
    "\n",
    "    outlier_ratio_path = f'./statistics/{c}/'\n",
    "    outlier_ratio_file = c+'Weather_ori_1_outlier_ratio.csv'\n",
    "    if not os.path.exists(outlier_ratio_path):\n",
    "        os.makedirs(outlier_ratio_path)\n",
    "    outlier_ratio_df.to_csv(outlier_ratio_path+outlier_ratio_file,\\\n",
    "                          index=True)\n",
    "\n",
    "outlier_ratio_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 先对其进行处理，使每小时内的所有数据取平均值\n",
    "（1）对于非数字的列，取第一次出现的  \n",
    "（2）对于数字的列，若非‘最高气温’和‘最低气温’这两列，则取平均值  \n",
    "（3）对于最高（最低）气温，取最大（最小）值  \n",
    "（4）把expire_time替换成修改前的valid_time，再由（1），则处理后的expire_time，即为每小时的第一条数据的具体时间  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYC Number of rows: 43431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43431/43431 [00:10<00:00, 4032.43it/s]\n",
      " 17%|█▋        | 806/4849 [00:00<00:00, 4084.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAY Number of rows: 4849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4849/4849 [00:01<00:00, 3933.42it/s]\n",
      "  1%|          | 375/43734 [00:00<00:11, 3749.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicago Number of rows: 43734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43734/43734 [00:10<00:00, 4074.68it/s]\n",
      "  0%|          | 0/47368 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DC Number of rows: 47368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47368/47368 [00:11<00:00, 4257.84it/s]\n",
      "  0%|          | 0/3197 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LA Number of rows: 3197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3197/3197 [00:00<00:00, 3936.24it/s]\n",
      "  0%|          | 517/240747 [00:00<00:46, 5168.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melbourne Number of rows: 240747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240747/240747 [00:43<00:00, 5508.19it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "cities_ls = ['NYC', 'BAY','Chicago','DC','LA','Melbourne']\n",
    "suffix = 'Weather_ori_1.csv'\n",
    "# col = ['STATION', 'STATION_NAME', 'ELEVATION', 'LATITUDE', 'LONGITUDE', 'DATE', 'REPORTTYPE', 'HOURLYSKYCONDITIONS', 'HOURLYVISIBILITY', 'HOURLYPRSENTWEATHERTYPE', 'HOURLYDRYBULBTEMPF', 'HOURLYDRYBULBTEMPC', 'HOURLYWETBULBTEMPF', 'HOURLYWETBULBTEMPC', 'HOURLYDewPointTempF', 'HOURLYDewPointTempC', 'HOURLYRelativeHumidity', 'HOURLYWindSpeed', 'HOURLYWindDirection', 'HOURLYWindGustSpeed', 'HOURLYStationPressure', 'HOURLYPressureTendency', 'HOURLYPressureChange', 'HOURLYSeaLevelPressure', 'HOURLYPrecip', 'HOURLYAltimeterSetting', 'DAILYMaximumDryBulbTemp', 'DAILYMinimumDryBulbTemp', 'DAILYAverageDryBulbTemp', 'DAILYDeptFromNormalAverageTemp', 'DAILYAverageRelativeHumidity', 'DAILYAverageDewPointTemp', 'DAILYAverageWetBulbTemp', 'DAILYHeatingDegreeDays', 'DAILYCoolingDegreeDays', 'DAILYSunrise', 'DAILYSunset', 'DAILYWeather', 'DAILYPrecip', 'DAILYSnowfall', 'DAILYSnowDepth', 'DAILYAverageStationPressure', 'DAILYAverageSeaLevelPressure', 'DAILYAverageWindSpeed', 'DAILYPeakWindSpeed', 'PeakWindDirection', 'DAILYSustainedWindSpeed', 'DAILYSustainedWindDirection', 'MonthlyMaximumTemp', 'MonthlyMinimumTemp', 'MonthlyMeanTemp', 'MonthlyAverageRH', 'MonthlyDewpointTemp', 'MonthlyWetBulbTemp', 'MonthlyAvgHeatingDegreeDays', 'MonthlyAvgCoolingDegreeDays', 'MonthlyStationPressure', 'MonthlySeaLevelPressure', 'MonthlyAverageWindSpeed', 'MonthlyTotalSnowfall', 'MonthlyDeptFromNormalMaximumTemp', 'MonthlyDeptFromNormalMinimumTemp', 'MonthlyDeptFromNormalAverageTemp', 'MonthlyDeptFromNormalPrecip', 'MonthlyTotalLiquidPrecip', 'MonthlyGreatestPrecip', 'MonthlyGreatestPrecipDate', 'MonthlyGreatestSnowfall', 'MonthlyGreatestSnowfallDate', 'MonthlyGreatestSnowDepth', 'MonthlyGreatestSnowDepthDate', 'MonthlyDaysWithGT90Temp', 'MonthlyDaysWithLT32Temp', 'MonthlyDaysWithGT32Temp', 'MonthlyDaysWithLT0Temp', 'MonthlyDaysWithGT001Precip', 'MonthlyDaysWithGT010Precip', 'MonthlyDaysWithGT1Snow', 'MonthlyMaxSeaLevelPressureValue', 'MonthlyMaxSeaLevelPressureDate', 'MonthlyMaxSeaLevelPressureTime', 'MonthlyMinSeaLevelPressureValue', 'MonthlyMinSeaLevelPressureDate', 'MonthlyMinSeaLevelPressureTime', 'MonthlyTotalHeatingDegreeDays', 'MonthlyTotalCoolingDegreeDays', 'MonthlyDeptFromNormalHeatingDD', 'MonthlyDeptFromNormalCoolingDD', 'MonthlyTotalSeasonToDateHeatingDD', 'MonthlyTotalSeasonToDateCoolingDD']\n",
    "col = ['key', 'class', 'expire_time_gmt', 'obs_id', 'obs_name', 'valid_time_gmt', \n",
    "         'day_ind', 'temp', 'wx_icon', 'icon_extd', 'wx_phrase', 'pressure_tend', \n",
    "         'pressure_desc', 'dewPt', 'heat_index', 'rh', 'pressure', 'vis', 'wc', \n",
    "         'wdir', 'wdir_cardinal', 'gust', 'wspd', 'max_temp', 'min_temp', \n",
    "         'precip_total', 'precip_hrly', 'snow_hrly', 'uv_desc', 'feels_like', \n",
    "         'uv_index', 'qualifier', 'qualifier_svrty', 'blunt_phrase', 'terse_phrase', \n",
    "         'clds', 'water_temp', 'primary_wave_period', 'primary_wave_height', \n",
    "         'primary_swell_period', 'primary_swell_height', 'primary_swell_direction', \n",
    "         'secondary_swell_period', 'secondary_swell_height', 'secondary_swell_direction']\n",
    "number_col = ['temp', 'pressure_tend', 'dewPt', 'heat_index', 'rh',\\\n",
    "              'pressure', 'vis', 'wc', 'gust',\\\n",
    "              'wspd', 'precip_total', 'precip_hrly', 'snow_hrly',\\\n",
    "              'feels_like', 'uv_index']\n",
    "special_col = ['max_temp','min_temp'] # TODO\n",
    "for c in cities_ls:\n",
    "    f_str = c + suffix # the name of the file\n",
    "    df_process = pd.read_csv(f_str)\n",
    "    num_rows = len(df_process)\n",
    "    print(c, \"Number of rows:\", num_rows)\n",
    "\n",
    "    df_process['expire_time_gmt'] = df_process['valid_time_gmt'].copy()\n",
    "    df_process['valid_time_gmt'] = df_process['valid_time_gmt'].apply(lambda x: str(x)[:-6])\n",
    "    \n",
    "\n",
    "    new_dict = {}\n",
    "    for col_name in col:\n",
    "        new_dict[col_name] = []\n",
    "    last_date = 0\n",
    "    tmp_dict = {}\n",
    "    same_cnt = 0\n",
    "\n",
    "    for i in tqdm(range(num_rows)):\n",
    "        now_date = df_process.loc[i, 'valid_time_gmt']\n",
    "        # DATE不相同，需要处理，其中前后边界需要特别处理\n",
    "        if last_date != now_date:\n",
    "            # 先把数据的列除以相同的行数，即转换为平均值\n",
    "            for col_name in number_col:\n",
    "                if i != 0: tmp_dict[col_name] /= same_cnt\n",
    "            # 取最大or最小值\n",
    "            if i != 0: tmp_dict['max_temp'] = max(tmp_dict['max_temp'])\n",
    "            if i != 0: tmp_dict['min_temp'] = min(tmp_dict['min_temp'])\n",
    "            # 然后把tmp_dict插入new_dict中\n",
    "            for col_name in col:\n",
    "                if i != 0 or i == num_rows-1: \n",
    "                    new_dict[col_name].append(tmp_dict[col_name])\n",
    "            # 并初始化新的tmp_dict\n",
    "            for col_name in col:\n",
    "                tmp_dict[col_name] = df_process.loc[i, col_name]\n",
    "            for col_name in number_col:\n",
    "                tmp_dict[col_name] = float(tmp_dict[col_name])\n",
    "            for col_name in special_col:\n",
    "                tmp_dict[col_name] = [float(tmp_dict[col_name])]\n",
    "                \n",
    "\n",
    "            # 开始新的一轮相同DATE的行的处理，初始化↓\n",
    "            same_cnt = 1\n",
    "            last_date = now_date\n",
    "\n",
    "        # DATE相同，加入到tmp_dict中\n",
    "        else:\n",
    "            # 计数加1\n",
    "            same_cnt += 1\n",
    "            # 直接加到tmo_dict（求和），最后再进行求平均值\n",
    "            # 对于不在number_col中的列，其为字符串无法取平均值，只保留第一个的数据，即上方初始化的值\n",
    "            for col_name in number_col:\n",
    "                tmp_dict[col_name] += float(df_process.loc[i, col_name])\n",
    "            # 对于最大值or最小值，先加入list中，后续再处理\n",
    "            for col_name in special_col:\n",
    "                tmp_dict[col_name].append(float(df_process.loc[i, col_name]))\n",
    "\n",
    "            # 特殊处理尾端\n",
    "            if i == num_rows-1:\n",
    "                # 先转化为平均值\n",
    "                for col_name in number_col:\n",
    "                    tmp_dict[col_name] /= same_cnt\n",
    "                # 取最大or最小值\n",
    "                tmp_dict['max_temp'] = max(tmp_dict['max_temp'])\n",
    "                tmp_dict['min_temp'] = min(tmp_dict['min_temp'])\n",
    "                # 然后把tmp_dict插入new_dict中\n",
    "                for col_name in col:\n",
    "                    new_dict[col_name].append(tmp_dict[col_name])\n",
    "\n",
    "    new_df = pd.DataFrame(new_dict)\n",
    "    process_path = f'./process/{c}/'\n",
    "    process_file = c+'Weather_1h.csv'\n",
    "    if not os.path.exists(process_path):\n",
    "        os.makedirs(process_path)\n",
    "    new_df.to_csv(process_path+process_file, index=False)\n",
    "\n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 按照train/test的视角去分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
